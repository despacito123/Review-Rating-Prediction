{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I consider the 5-core dataset of reviews for movies and TV on Amazon, in which all users and items have at least 5 reviews. The dataset can be downloaded at this [website](http://jmcauley.ucsd.edu/data/amazon/). The task is to predict the ratings. Two different types of model can be exploited for this kind of dataset. The first type is collabrative filtering based on the reviewer-item rating matrix. The second is a classifier based purely on the review text content. I will first try both methods independently, and then check if combination of two methods can lead to better performance.\n",
    "\n",
    "# I. Data Aquisition\n",
    "\n",
    "First download the *reviews_Movies_and_TV_5.json.gz* file from the [website](http://jmcauley.ucsd.edu/data/amazon/). Then use the following code to read into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Movies_and_TV_5.json.gz')\n",
    "# df.to_csv(\"reviews_Movies_and_TV_5.csv\") # write to disk for future use\n",
    "# df = pd.read_csv('reviews_Movies_and_TV_5.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use 70% of the entire dataset as training set, 20% as cross validation (CV) set, and 10% as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numOfReviews = len(df)\n",
    "\n",
    "N_train = numOfReviews*7/10\n",
    "N_cv = numOfReviews*2/10\n",
    "N_test = numOfReviews - N_train - N_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Biased Matrix Factorization (MF) Based on Reviewer-Item Rating Matrix\n",
    "\n",
    "I use the [MyMediaLite](http://www.mymedialite.net/) software to build the biased matrix factorization model. A good introduction to biased matrix factorization can be found at this [site](http://activisiongamescience.github.io/2016/01/11/Implicit-Recommender-Systems-Biased-Matrix-Factorization/).\n",
    "In the following, I first randomly shuffle the original data, extract the userId, productId, and ratings to form the dataframe **ratings**. I then divide the ratings dataframe into training, cross validation and test set, and save them as csv file to feed for the MyMediaLite software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df.sample(frac = 1) # random shuffle\n",
    "del df\n",
    "# df2.to_csv(\"shuffled_reviews_Movies_and_TV_5.csv\")\n",
    "\n",
    "ratings = df2[['reviewerID', 'asin', 'overall']]\n",
    "ratings.iloc[0 : N_train, :].to_csv(\"ratings_Movies_and_TV_5_train.csv\", index = False, header = False)\n",
    "\n",
    "ratings_cv = ratings.iloc[N_train : N_train + N_cv, :]\n",
    "ratings_cv.index = range(0, len(ratings_cv))\n",
    "ratings_cv.to_csv(\"ratings_Movies_and_TV_5_cv.csv\", index = False, header = False)\n",
    "\n",
    "ratings_test = ratings.iloc[-N_test :, :]\n",
    "ratings_test.index = range(0, len(ratings_test))\n",
    "ratings_test.to_csv(\"ratings_Movies_and_TV_5_test.csv\", index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Download](http://www.mymedialite.net/download/index.html) the MyMediaLite binary package and use the following command to train biased MF model and make prediction on validation set and test set repectively:\n",
    "\n",
    "```\n",
    "./rating_prediction --recommender=BiasedMatrixFactorization --recommender-options=\"num_factors=20 bias_reg=0.001\" --training-file=ratings_Movies_and_TV_5_train.csv --test-file=ratings_Movies_and_TV_5_cv.csv --prediction-file=prediction_cv.csv\n",
    "\n",
    "./rating_prediction --recommender=BiasedMatrixFactorization --recommender-options=\"num_factors=20 bias_reg=0.001\" --training-file=ratings_Movies_and_TV_5_train.csv --test-file=ratings_Movies_and_TV_5_test.csv --prediction-file=prediction_test.csv\n",
    "\n",
    "```\n",
    "The above command produces prediction files \"prediction_cv.csv\" and \"prediction_test.csv\" for the validation set and test set respectively. We read the CV file and calculate the root mean square error (RMSE) and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix factorization: RMSE is 1.03371225856\n",
      "matrix factorization: accuracy is 0.43604236744\n"
     ]
    }
   ],
   "source": [
    "MF_pred_cv = pd.read_csv(\"prediction_cv.csv\" ,sep=\"\\t\", header=None)\n",
    "MF_pred_test = pd.read_csv(\"prediction_test.csv\" ,sep=\"\\t\", header=None)\n",
    "\n",
    "MF_RMSE_cv = np.sqrt(np.sum((MF_pred_cv.iloc[:,2] - ratings_cv['overall'])**2)/N_cv)\n",
    "print(\"matrix factorization: RMSE is\", MF_RMSE_cv)\n",
    "\n",
    "MF_ratingPred_cv = np.round(MF_pred_cv.iloc[:, 2]) # round to integer ratings\n",
    "MF_accuracy_cv = sum(MF_ratingPred_cv==ratings_cv['overall'])*1.0/N_cv\n",
    "print(\"matrix factorization: accuracy is\", MF_accuracy_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Classifier Based on Review Text Content\n",
    "\n",
    "In the next, we will use word count vector of the review text and/or summary text as features to build classifer. We will try naive Bayes, logistic regression and linear regression. \n",
    "\n",
    "## Feature Selection\n",
    "\n",
    "The dataset comes with a default vocabulary containing all the words appearing in the training set. The performance of classification algorithms on such a huge vocabulary might be poor. There are diffrent ways to reduce the size of the vocabulary (dictionary). Since I don't have enough time to check all the different dictionaries to identify the best feature set (features being words), I would just utilize some of the findings in previous work. For example, [this work](http://cs229.stanford.edu/proj2011/MehtaPhilipScaria-Predicting%20Star%20Ratings%20from%20Movie%20Review%20Comments.pdf) shows that word stemming reduces performance, removing stop words improves performance largely, identifying negation of context and including frequent bigrams does not improve performance, dliminating words that have very less information results in improvement in performance. **Given the above findings, I will construct unigram word count vector from the review texts with standard English stop-words removed. I will also ignore words that have a document frequency strictly lower than a threshold min_df.** One consideration of using a min_df is to reduce the dimension of the feature, otherwise the logistic regression may take too long to train.\n",
    "\n",
    "Because naive Bayes algorithm is fast to train, I will use naive Bayes to select best min_df and check the performance of using review and/or summary texts as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the true ratings for training set and validation set for later use\n",
    "\n",
    "target_train = df2['overall'][0:N_train]\n",
    "target_train.index = range(N_train)\n",
    "\n",
    "trueRating_cv = df2['overall'][N_train: N_train+N_cv]\n",
    "trueRating_cv.index = range(N_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to calculate accuracy and RMSE on validation set\n",
    "def scoresOnCV(model, wordvec, description):\n",
    "    prediction = model.predict(wordvec[N_train: N_train+N_cv])\n",
    "    accuracy = np.sum(trueRating_cv == np.round(prediction))*1.0/N_cv\n",
    "    print(description + \": accuracy is \"+ str(accuracy))\n",
    "    RMSE = np.sqrt(np.sum((trueRating_cv - prediction)**2)/N_cv)\n",
    "    print(description + \": RMSE is \"+ str(RMSE))\n",
    "\n",
    "    return accuracy, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the word count vector **wordvec** with standard English stop-words and a min_df = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the review texts onto disk, and the vectorizer reads from the disk to build the word count vectors\n",
    "# There will be memory issues if I directly pass the pd dataframe to the vectorizer\n",
    "df2['reviewText'].to_csv(\"corpus.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = open('corpus.txt')\n",
    "vectorizer = CountVectorizer(stop_words = 'english', min_df=0.001)\n",
    "wordvec = vectorizer.fit_transform(corpus)\n",
    "# wordvec = vectorizer.fit_transform(df2['reviewText'].values.astype('U')) # this line may lead to memory issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1697533, 7762)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df = 0.001\n",
      "multinomial naive Bayes: accuracy is 0.582019169028\n",
      "multinomial naive Bayes: RMSE is 1.17076284672\n"
     ]
    }
   ],
   "source": [
    "print('min_df =', 0.001)\n",
    "\n",
    "mnb_clf = MultinomialNB()\n",
    "\n",
    "mnb_clf.fit(wordvec[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec, \"multinomial naive Bayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli naive Bayes: accuracy is 0.527266086608\n",
      "Bernoulli naive Bayes: RMSE is 1.21038852531\n"
     ]
    }
   ],
   "source": [
    "bnb_clf = BernoulliNB()\n",
    "\n",
    "bnb_clf.fit(wordvec[0:N_train], target_train)\n",
    "bnb_accuracy_cv, bnb_RMSE_cv = scoresOnCV(bnb_clf, wordvec, \"Bernoulli naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I modify min_df to 0.0001 and build **wordvec2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df = 0.0001\n",
      "multinomial naive Bayes: accuracy is 0.579762949698\n",
      "multinomial naive Bayes: RMSE is 1.18344819156\n",
      "Bernoulli naive Bayes: accuracy is 0.528659287317\n",
      "Bernoulli naive Bayes: RMSE is 1.20902013615\n"
     ]
    }
   ],
   "source": [
    "corpus = open('corpus.txt')\n",
    "vectorizer2 = CountVectorizer(stop_words = 'english', min_df=0.0001)\n",
    "wordvec2 = vectorizer2.fit_transform(corpus)\n",
    "\n",
    "print('min_df =', 0.0001)\n",
    "\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_clf.fit(wordvec2[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec2, \"multinomial naive Bayes\")\n",
    "\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(wordvec2[0:N_train], target_train)\n",
    "bnb_accuracy_cv, bnb_RMSE_cv = scoresOnCV(bnb_clf, wordvec2, \"Bernoulli naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I try min_df = 0.01 for **wordvec3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df = 0.01\n",
      "multinomial naive Bayes: accuracy is 0.577618657697\n",
      "multinomial naive Bayes: RMSE is 1.18720540817\n",
      "Bernoulli naive Bayes: accuracy is 0.518824409583\n",
      "Bernoulli naive Bayes: RMSE is 1.25180588008\n"
     ]
    }
   ],
   "source": [
    "corpus = open('corpus.txt')\n",
    "vectorizer3 = CountVectorizer(stop_words = 'english', min_df=0.01)\n",
    "wordvec3 = vectorizer3.fit_transform(corpus)\n",
    "\n",
    "print('min_df =', 0.01)\n",
    "\n",
    "mnb_clf.fit(wordvec3[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec3, \"multinomial naive Bayes\")\n",
    "\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(wordvec3[0:N_train], target_train)\n",
    "bnb_accuracy_cv, bnb_RMSE_cv = scoresOnCV(bnb_clf, wordvec3, \"Bernoulli naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, I use the summary text only to build the word count vector **wordvec4**. Since the Bernoulli naive Bayes always performs worse than the multinomial naive Bayes, I will only test for multinomial naive Bayes in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial naive Bayes: accuracy is 0.581798259825\n",
      "multinomial naive Bayes: RMSE is 1.19318568138\n"
     ]
    }
   ],
   "source": [
    "vectorizer4 = CountVectorizer(stop_words = 'english')\n",
    "wordvec4 = vectorizer4.fit_transform(df2['summary'].values.astype('U'))\n",
    "\n",
    "mnb_clf.fit(wordvec4[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec4, \"multinomial naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model using summary text is actually as good as the model using the entire review text. I then add the review text and summary text together to form a new text and use the new text to build the word count vector **wordvec5** with min_df = 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['reviewTextandSummary'] = df2['reviewText'] + df2['summary']\n",
    "df2['reviewTextandSummary'].to_csv(\"corpus2.txt\", index=False)\n",
    "\n",
    "corpus2 = open('corpus2.txt')\n",
    "\n",
    "vectorizer5 = CountVectorizer(stop_words = 'english', min_df=0.001)\n",
    "wordvec5 = vectorizer5.fit_transform(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial naive Bayes: accuracy is 0.595883430632\n",
      "multinomial naive Bayes: RMSE is 1.1114540729\n"
     ]
    }
   ],
   "source": [
    "mnb_clf.fit(wordvec5[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec5, \"multinomial naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above feature **wordvec5** gives the best accuracy so far.\n",
    "\n",
    "In the next, I eliminate words with low information, using same method as this previous [work](http://cs229.stanford.edu/proj2011/MehtaPhilipScaria-Predicting%20Star%20Ratings%20from%20Movie%20Review%20Comments.pdf). Starting with wordvec5, The ratio of number of occurrences of each word in positive comments (4, 5 star ratings) and negative comments (1, 2 ratings) are counted and those words with positive-count/netative-count > 2 or netative-count/positive-count> 2 are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "\n",
    "allratings = df2['overall']\n",
    "allratings.index = range(numOfReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select words with information: done in 2774.081s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "select = []\n",
    "for i in range(wordvec5.shape[1]):\n",
    "    rows, columns, values = find(wordvec5[:, i])\n",
    "    positive = np.sum(values[allratings[rows] > 3])\n",
    "    negative = np.sum(values[allratings[rows] < 3])\n",
    "    if(positive*negative == 0 or positive/negative > 2 or negative/positive > 2):\n",
    "        select.append(i)\n",
    "        \n",
    "print(\"select words with information: done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multinomial naive Bayes: accuracy is 0.561645449565\n",
      "multinomial naive Bayes: RMSE is 1.29553774722\n"
     ]
    }
   ],
   "source": [
    "wordvec6 = wordvec5[:,select]\n",
    "mnb_clf.fit(wordvec6[0:N_train], target_train)\n",
    "mnb_accuracy_cv, mnb_RMSE_cv = scoresOnCV(mnb_clf, wordvec6, \"multinomial naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After elimilating low-information words from the **wordvec5**, the accuray actually becomes lower than using the original **wordvec5** feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "In the above, I have found the optimal feature, **wordvec5**, namely the word count vector of the combined text of review and summary, with min_df = 0.001. The multinomial naive Bayes classifier obtains an accuracy of 0.596 and a RMSE of 1.111 with this feature. In the next, we will try logistic regression and linear regression. Note that for linear regression, the prediction is rounded to nearest integer when calculating accuracy, but remains decimal when calculating RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression: accuracy is 0.403433223566\n",
      "linear regression: RMSE is 0.930900482216\n",
      "linear regression: done in 311.523s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "linear_reg = Ridge(alpha=0.1)\n",
    "linear_reg.fit(wordvec5[0:N_train], target_train)\n",
    "lreg_accuracy_cv, lreg_RMSE_cv = scoresOnCV(linear_reg, wordvec5, \"linear regression\")\n",
    "\n",
    "print(\"linear regression: done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression: accuracy is 0.640097671322\n",
      "logistic regression: RMSE is 0.977248202774\n",
      "logistic regression training: done in 1116.553s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "logistic_clf = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=300) \n",
    "logistic_clf.fit(wordvec5[0:N_train], target_train)\n",
    "logi_accuracy_cv, logi_RMSE_cv = scoresOnCV(logistic_clf, wordvec5, \"logistic regression\")\n",
    "\n",
    "print(\"logistic regression training: done in %0.3fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classfier model among all I investigated is the logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Combining MF and Classifier \n",
    "\n",
    "The simplest way to combine the MF and classifier (CLF) is to add their predictions with some weights:\n",
    "\\begin{equation}\n",
    "Prediction = \\alpha*Prediction_{CLF} + (1-\\alpha)*Prediction_{MF}\n",
    "\\end{equation}\n",
    "I will combine the MF and the logistic regression model above, and find the best parameter $\\alpha$ through validation set.\n",
    "\n",
    "A previous [work](https://www.hindawi.com/journals/cin/2016/5968705/) combining these two kinds of models define the hypothesis as a combination of the two using the same scheme as above. Then they minimize the cost function according to the combined hypothesis, so that they train the parameters in MF and CLF together. My method is to train the MF and CLF independently and combine their prediction at last step. I think their method should perform better but I don't have time to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combination model with alpha = 0.00: accuracy is 0.436042\n",
      "RMSE is 1.03371225856\n",
      "Combination model with alpha = 0.02: accuracy is 0.442357\n",
      "RMSE is 1.02097852466\n",
      "Combination model with alpha = 0.04: accuracy is 0.448428\n",
      "RMSE is 1.00856754083\n",
      "Combination model with alpha = 0.06: accuracy is 0.454213\n",
      "RMSE is 0.996491366393\n",
      "Combination model with alpha = 0.08: accuracy is 0.460392\n",
      "RMSE is 0.984762318768\n",
      "Combination model with alpha = 0.10: accuracy is 0.466339\n",
      "RMSE is 0.973392946307\n",
      "Combination model with alpha = 0.12: accuracy is 0.472590\n",
      "RMSE is 0.962395996284\n",
      "Combination model with alpha = 0.14: accuracy is 0.478634\n",
      "RMSE is 0.951784377731\n",
      "Combination model with alpha = 0.16: accuracy is 0.484893\n",
      "RMSE is 0.941571118932\n",
      "Combination model with alpha = 0.18: accuracy is 0.491535\n",
      "RMSE is 0.931769319418\n",
      "Combination model with alpha = 0.20: accuracy is 0.497423\n",
      "RMSE is 0.922392096397\n",
      "Combination model with alpha = 0.22: accuracy is 0.503753\n",
      "RMSE is 0.91345252568\n",
      "Combination model with alpha = 0.24: accuracy is 0.509526\n",
      "RMSE is 0.90496357724\n",
      "Combination model with alpha = 0.26: accuracy is 0.516150\n",
      "RMSE is 0.89693804573\n",
      "Combination model with alpha = 0.28: accuracy is 0.522271\n",
      "RMSE is 0.889388476377\n",
      "Combination model with alpha = 0.30: accuracy is 0.528547\n",
      "RMSE is 0.882327086874\n",
      "Combination model with alpha = 0.32: accuracy is 0.534488\n",
      "RMSE is 0.875765686035\n",
      "Combination model with alpha = 0.34: accuracy is 0.539876\n",
      "RMSE is 0.869715590138\n",
      "Combination model with alpha = 0.36: accuracy is 0.545666\n",
      "RMSE is 0.864187538043\n",
      "Combination model with alpha = 0.38: accuracy is 0.551781\n",
      "RMSE is 0.859191606322\n",
      "Combination model with alpha = 0.40: accuracy is 0.557118\n",
      "RMSE is 0.854737125744\n",
      "Combination model with alpha = 0.42: accuracy is 0.562591\n",
      "RMSE is 0.850832600552\n",
      "Combination model with alpha = 0.44: accuracy is 0.567863\n",
      "RMSE is 0.847485632024\n",
      "Combination model with alpha = 0.46: accuracy is 0.572912\n",
      "RMSE is 0.844702847809\n",
      "Combination model with alpha = 0.48: accuracy is 0.578323\n",
      "RMSE is 0.842489838511\n",
      "Combination model with alpha = 0.50: accuracy is 0.583327\n",
      "RMSE is 0.840851102858\n",
      "Combination model with alpha = 0.52: accuracy is 0.588596\n",
      "RMSE is 0.839790002707\n",
      "Combination model with alpha = 0.54: accuracy is 0.593012\n",
      "RMSE is 0.839308728897\n",
      "Combination model with alpha = 0.56: accuracy is 0.597197\n",
      "RMSE is 0.839408278757\n",
      "Combination model with alpha = 0.58: accuracy is 0.601218\n",
      "RMSE is 0.840088445804\n",
      "Combination model with alpha = 0.60: accuracy is 0.605011\n",
      "RMSE is 0.841347821884\n",
      "Combination model with alpha = 0.62: accuracy is 0.608861\n",
      "RMSE is 0.843183811687\n",
      "Combination model with alpha = 0.64: accuracy is 0.611842\n",
      "RMSE is 0.84559265931\n",
      "Combination model with alpha = 0.66: accuracy is 0.614469\n",
      "RMSE is 0.848569486225\n",
      "Combination model with alpha = 0.68: accuracy is 0.617468\n",
      "RMSE is 0.852108339774\n",
      "Combination model with alpha = 0.70: accuracy is 0.619939\n",
      "RMSE is 0.856202251083\n",
      "Combination model with alpha = 0.72: accuracy is 0.622313\n",
      "RMSE is 0.860843301126\n",
      "Combination model with alpha = 0.74: accuracy is 0.624540\n",
      "RMSE is 0.866022693532\n",
      "Combination model with alpha = 0.76: accuracy is 0.626546\n",
      "RMSE is 0.871730832665\n",
      "Combination model with alpha = 0.78: accuracy is 0.628607\n",
      "RMSE is 0.877957405465\n",
      "Combination model with alpha = 0.80: accuracy is 0.630979\n",
      "RMSE is 0.884691465591\n",
      "Combination model with alpha = 0.82: accuracy is 0.633833\n",
      "RMSE is 0.891921518439\n",
      "Combination model with alpha = 0.84: accuracy is 0.636442\n",
      "RMSE is 0.899635605735\n",
      "Combination model with alpha = 0.86: accuracy is 0.639182\n",
      "RMSE is 0.907821388514\n",
      "Combination model with alpha = 0.88: accuracy is 0.640098\n",
      "RMSE is 0.916466227456\n",
      "Combination model with alpha = 0.90: accuracy is 0.640098\n",
      "RMSE is 0.925557259697\n",
      "Combination model with alpha = 0.92: accuracy is 0.640098\n",
      "RMSE is 0.93508147141\n",
      "Combination model with alpha = 0.94: accuracy is 0.640098\n",
      "RMSE is 0.945025765605\n",
      "Combination model with alpha = 0.96: accuracy is 0.640098\n",
      "RMSE is 0.955377024754\n",
      "Combination model with alpha = 0.98: accuracy is 0.640098\n",
      "RMSE is 0.966122167991\n",
      "Combination model with alpha = 1.00: accuracy is 0.640098\n",
      "RMSE is 0.977248202774\n"
     ]
    }
   ],
   "source": [
    "def scoresOfCombinationModel(clf_pred, mf_pred, alpha):\n",
    "    prediction = clf_pred*alpha + mf_pred*(1-alpha)\n",
    "    accuracy = np.sum(trueRating_cv == np.round(prediction))*1.0/N_cv\n",
    "    print(\"Combination model with alpha = %.2f: accuracy is %.6f\" % (alpha, accuracy))\n",
    "    RMSE = np.sqrt(np.sum((trueRating_cv - prediction)**2)/N_cv)\n",
    "    print(\"RMSE is\", RMSE)\n",
    "\n",
    "    return accuracy, RMSE\n",
    "\n",
    "accuracies = []\n",
    "RMSEs = []\n",
    "def selectAlpha(clf_pred, mf_pred):\n",
    "    maxAccu, best_alpha = 0, -1\n",
    "    for alpha in np.arange(0, 1.02, 0.02):\n",
    "        accu, RMSE = scoresOfCombinationModel(clf_pred, mf_pred, alpha)\n",
    "        accuracies.append(accu)\n",
    "        RMSEs.append(RMSE)\n",
    "        if(accu > maxAccu):\n",
    "            maxAccu = accu\n",
    "            best_alpha = alpha\n",
    "    return best_alpha\n",
    "\n",
    "clf_pred = logistic_clf.predict(wordvec5[N_train: N_train+N_cv])\n",
    "mf_pred = MF_pred_cv.iloc[:,2]\n",
    "\n",
    "optimalAlpha = selectAlpha(clf_pred, mf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimalAlpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal alpha = 0.88 leads to an accuracy of 0.6401 and a RMSE of 0.9165."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAGHCAYAAAA+xRHwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3Xd8VMX6+PHPE0ILgSCG3kJvSkkQRUVAigiiNJUmiBS9\niNfLvdarouj1+tP7xYKKIoKghEgHC0pVQGmaAArSEwggVXoJIcn8/pizcbPZbIpJNoHn/XrtK9nZ\nOWfmnD3lOTNzzooxBqWUUkqpjAT4uwJKKaWUKtg0WFBKKaWUTxosKKWUUsonDRaUUkop5ZMGC0op\npZTySYMFpZRSSvmkwYJSSimlfNJgQSmllFI+abCglFJKKZ80WMgjIjJVRM5mMW+KiIzJ6zoVFCLy\nkoik5OL8popIXG7NT1lXw3ot7MsoIntFZIq/61FQicgBEfnoaik3L10xwYKI1BaRiSKyR0Quishp\nEflBRP4uIiX8UCXjvHI7b64RkcFOoBKez0UbIFvBgohUFpEXRaRpbszPRzmfOOvE9UoQkR0iMlZE\niudGGYVIrq3XAixL+56IfO9sDzsy+Lyj2zbTK7uVEJFGzvZdI5uTppBLxw4Rqemx7bu/1uRGGV7K\nvMVZ7uC8mD+5uH48ZVL3PCvXXwL9XYHcICLdgFlAAvApsAUoBtwKvAE0Bh7xWwUzVxJI8lPZ/tig\nXwFey+Y0VYAXgTjgF4/PhpG7gW8CMBQQIAS4B3gBqA08kIvlFHS5vV4LMwNcBOqKSEtjzM8enw9w\nPs/phUlj7Pb9HRCfjekakPsB3QxgkUfasVwuw+VWYAwwCTiXB/OvAyTnwXzBd93zsly/KPTBgoiE\nAVHYk8jtxpijbh9/ICIvAN38ULUsM8Yk+rsO+ckYkwJkd5nFx/ySyd0dM8kYE+X2/gPnyqqfiPzT\nGJNXB06vRCTIGHMhP8uEPFmvhd0e7DGzH5AaLDgtTj2Br4HeOZy3kI3AXURKGGMSjDGXc1ieLzHG\nmBl5MF9vMtyv/9JM83b9pBaT0Qd5XK5fXAlXDU8DpYChHoECAMaYWGPMu673IlJERF4Qkd1OE3Oc\niLwqIsXcp3P6Ar8QkbYi8pOIXBCRX0SkrfN5L+f9RRH5WUSae6uciNQSkcUick5EDjrBi2eeNGMW\nXH36IlLH6VM9KSKnRGSKty4VERno1OGCiPwhIlEiUi07K9EXESkvIpNF5LCzvJtEZJCXfOVE5DOn\nC+ik06Tf1FmWQW750o1ZEJFOIrLame6siGwXkVedz9oCG7AH06nO/JJd8xQv/c5iPe72HR0VkW/+\nQpfLD9iDQ20v5fxDRLY45RwWkQ9FpKyXfC8528B5EVnuND2n6XOWP7uGbhORCSJyBNjv9nkVZzs4\n7Gy/W0RkiGdlReQx57PzInLC2Yb7un0eLCJvO9t/gogcEZEl7ttxBus1SETGiUi8M912EfmXl/JT\nRGS8iNwjIr+61fWOzFa0iBQVkZedbfqUs++sEpF2Hvlczeb/FJHh8uc+vUFEWnqZbw+37+kXEemR\nWV28iALu90i7G9s6OAuPE4iI1HC+x+3O/nlcRGaJSE23PIOdaQFc3R3JInKb87nrWNTZ+R4vAiPc\nPnPfflY423qoW1pR5zvYJSIlc7DMaYg9Js522wb2icj/iZduOmcbny0ix5zl3yYiY53PXgH+62Q9\n4LbcVZzPA8U28+9xyol1touiHmUcEJF5ItLF2WYSgIfcPvvI+b+IZNzNkuJWbjMRmeaUlyAih0Rk\nkohc41ZmZnVPN2ZB7PF8jrM/nheRNZ77g4h0cObVU+x56oCz3paKSK0cfmW5otC3LAB3AbHGmPVZ\nzD8ZGITdOf8PuBF4FmhI2qsCA9QDIoGJwGfAk8AXIvI34FXgfezB4d/ATGyToLtA4FtgrTNtF2Cs\niBQxxrzko46uK4xZQCzwDBCObRY+4tQXABF5DngZ+BzbHFYe+DuwUkRaGGPOZGGdZEhscLISe5J8\nF9gL3Is9aYe4AjEREeAroCUwAdiBbb6fRvorpjT9xCLSGPgS2IRt7r8E1AVudrJswzb3vYz9LlY7\n6Wu8zc8xBRiMvdqbhP0u2gA3ATHZXQ+Aa0c96ZH+EXZ7mgK84+R7DGguIrc4V+cA/w+7DSwElgDN\ngMVARuMgJgBHgbHYYBgRqQCsx17tjweOA3cCk0WktDFmvJNvuFOXWcDb2Kbxptht/XNn/hOBXtjv\ndBtwLbZZtRH2ewDv6/VLoC3wMbAZuAP4n4hUMcZ4Bg1tnDImAGex2+UcEalhjPFcj+7KYA/2Udj1\nWxrbLfStiLQyxnh2Qw0AgoEPnfo+DcwVkdqu9S8inYE52C7KZ5zl/QQ44KMe3szA7sPtjDHfO2n9\ngOV4b6q/AbvNRTllhQEjge9EpLExJgG7f43Hbjf/AbY7025z/hrs8WkG9nv7CLt/uT5z9xC2m+5D\noI+T9jL2e21rjLmYhWUMEpFrPdJOG2NcXaX3Ybfb94ATzvI9DlTGfhcAiA08V2K79T7Adq/Uxbb0\nvgjMdt7fB4wCTjmTnnD+TgX6Y7fZ1U45z2OPs+4BmwGaANOd5Z5I2nVn/zEmWUQGeiyXYE/61wDn\nnbQ7gOrYc8Vh4DrgYew6vNXJMyuTuqf5XkSkEvZ4VRT7XZ8CHgS+FpEexpivPOr1PHAZeB0oBzyF\n7WJvg78YYwrtC3sQSQHmZTF/Uyf/hx7pb2APwG3d0uKctFZuaZ2c6c8BVd3Shzt5b3NL+8RJe8uj\nrC+xfZvl3NJSgDFu71900j7ymHYucNTtfQ3sBvW0R77G2Gb+ZzJZH4OdOob7yPO4k6evW1oR4Efg\nNFDKSevl1HmUx/TLnOkHeSxfspcyrvFRjwhn/oO8fPYJNmB0vW/v5H0zB9vUJ8AZ7MnkWmyQ9C+n\nfps88t7qlHO/R7prO+nrvK/gfB9zPPKNcfJN8fhOUoDvAfHI/zH2hFPWI30G9iBV3Hk/H/glk+U8\nCYzPwrpwX6/3OHV7xiPfLOyYm1oe2/RFIMwt7XonfWQm5QoQ6JFWBjgETHJLq+nM7yhQxi29u/N9\ndXVL2+isu2C3tA7O9LG+6uPk/c61TrGtXB85/4dgT4YDsEFUCtDLbbriXubVysk3wC2tNx7HELfP\nXMeijhl8NsUjbbgz/37YAPEy8H9ZWEbX+kx2/qa4vb8tk2V6ztkGKrul/ehsl5V9lPm0M/8qHunh\nTtnveaS/6eS/xS1tv5PWzsv89+NxHPX4/Fln2vsyWb4BTr4bM6u7t3KxQXkycINbWmnsxddOL9vk\nZqCIW/poZ/r6mX2PefUq7N0QZZy/WbpFEeiKjfje8kgfhz1AeY5t+M0Ys8Htvav1Yrkx5qBHerom\nasf7Hu/fww6+7JhJXQ02Qna3GrhW/hx929spd7aIXOt6YQ+eu7Anzb/qTuCwMcZ1RYqxV2vjsVdz\nbZ3kLtgT4sce07taX3xxReU9nRaKv6o3dod7OYfTB2OvEo8Bu4H/YbshPJut+2Drvtxj/W/EBpSu\n9d8RG2B94DH9u3hnsCdFz6vGXthgs4hHeUuAstgDLE6dqomXpng3p4AbRaSyjzye7sSeEDzrPQ7b\npXmnR/pSY8xe1xtjzK/YQMzbfoJbPmOcq1ixrsHuMz/z5zK6+9ykbUFbjdv+6FzVNQOmGmNSB6IZ\nY5YDv/mqSwZmAL1EJBDbypYELMhgWS65/nea1cthWwtPZbAsGYkzxizLSkZjzCRsi+Z72KvRXdiT\neVZ9hN1mXa9O2JOXa/7uy+RqhViDXefNnfSKQGvsdnwoG2W7ZPdYvcv82dKTJSLSCTvY+k1jjKsb\nyHP5ijvL5zrG57Qb805gjTHmJ7dyzmJbPeuISH2P/JPNn62S4LFN+0NhDxZcB4jSWczvipx3uyca\nY45gd96aHvnjPfK5yvNsujzt/L3GIz0Fe2BwtxP7pYdlob6eo6JdTbeucupiv8Pd/HlyO4YNFhpi\nr2j/qprYg42nbdjlcK2zGsAhY5tV3e0mczOxVyGTgCNix1zc+xcCh9rA78aYU5nm9O4iNsLviG0q\n/A27Lj2bcOthT9JHSb/+S/Hn+nfdDue53Z0kfbeGy173NyJS3ilrhEdZx7BdIMatvNexwcoGEdkp\nIu+JyM2k9RS2eXW/iKx3+oYz6xOtiV2v5z3St7l97m4/6Z0k/X6SjtixG5uxV+1/YNdpN+yVvKc0\n5bh9765yXPXyti16vRUyE5879eiKbSb/yss6AWw3ntPPHo/tXjuOXZYQvC9LRuIyz5LGMCAIe4wY\n4n4CzIJdxpgVHi/XMc41VuRTEfkDu50dw3bDwJ/LVMf5uzWb9XapiR1ovMc90blIO0v6bS1b60fs\nLaozsC1GT3l8dq2IvCt2vNBF7PLtxO5j2fnO3NXA+7aW1X3H89if7wr1mAVjzFkR+R170MvWpFnM\nl9FI8IzSc3tkb2blBGADki54v30qL25FynVOgHGbiLTHnhC6YPskl4tIZy9X2Hkt2RjzneuNiCzB\n9iNPJG3rQgB2DEl/vH/3f+WuCc/AxBXYT8eOA/HmFwBjzHYRaYAdz9MF2yIxUkTGGmPGOnlmi8gq\n7Cj+zsATwNMi0tMYs/gv1NtdjvYTp1/5E2AetovwqDOvf+P9yiq/9kcAjDGHRWQltnvqZuz6zch7\n2K6lt4B12AsLgw2Qs3OxlpWxBu7aY8cVGGz3T1bHdPkkIkWwXYulsX39O4AL2JPhFPx3AZrl9SN2\nMPtcbNDR18vxZS622/N17D51HjvWYBH5t3z5uk1nRaEOFhxfAcNF5EaT+SDHfdgvux5uUZ4zcKys\n83luCsAe3NyvaFyDIPfmwvz3YDeevcaYrFzB58Q+7MHGUyPn7163fO3EuWXJLV+9rBbknKC/A54Q\nkWexg73aAyvI3vMg9gCdRaTsX2hdcK/XYRF5CxjjDLBzdU3twbZArMnkys21XdV1+x+nSTqrVwrH\nsAe3IsaYFVmo80XsALLZTnP5fOA5EXnNOLfqOi1qHwIfih09vxHbXJ1RsLAP6CAipTyupBu5fZ4b\negN7jDF93BNFJKfdSq56edsWPQclZ9UMbJfbCeAbH/l6Y7s/Uq9exd41UNYjX64FxE7X0njs95gI\njBORxcYYby092dUc22rQzxgz063MLh75XC0CmV3IZbTc+4BAEanj3rrg3G1Qmr+2rU3Ajuu6xRjz\nh/sHTpfDbcCzxpjX3dIbZqPu3sTjfVvL7X0nzxT2bgiwVx4XgI+dk34aYm9X+bvzdhH25PoPj2z/\nwn7xX+dB/UZ5eZ/In812f8U8bIvCi94+dE5Gf9UioJKIpI4+dq4uHsOevFY5yYux/crD3fIJ8CiZ\n7FTidkuSm83Y78p1t4Dr5OR5kPVmLnbb9rpecuhd7NXLM25ps7ABd7pHdYu9TcvVZLkce6XwN49s\nj2W1cGOfTTEX6C0iTbyU536rXDmPaZP4s9uoqIgEiEgZjzzHgd/J+O4MsNtCIOm36dHY7dDXSTM7\n0l1ViciN2D7wbDPGHMbe4TFYRFK7LJ0+68Y5rOMc4CXgUfPnXQLeJJP+OPt37BgWd+ex309Wtu/M\nTHLm9RB2FH8SdmR/bnB9N6nL5Oznj5P2zoMj2HEMw0Skqo/5ZbRf58mx2rlTaAjwsDFmk5cs6ZbP\nMZr0x7HsHJMWATe7jyNyxp4NB3YbY3a65c3vltQsKfQtC8aYWBFx3V6zTUTcn+B4C3YQ2idO3l9E\nZBowwjlBrcSOFh6EvaNiZS5X7xLQRUSmYpsBu2IHurzqGdHmhLPszwP/dfqbF2BP4LWxzeUTsaOH\nfRFgqIh4Dk4De9vdR9gDzlRnQ9+LHdTVGnjc7QpzAXaU+DgRqYdttr+bP3ckXzvAGLH3lH+NjbAr\nYk+s8diBhWCvVE4Bj4jIOeyOus4Yky4iN8Z8LyKfAX93Bg59i9352wArjDETfK+S9IwxJ0TkE+Bv\nItLAGLPDGLNKRCYCz4i9TWwJduR5fex293fsdnVURN4B/ikiC536NMNuC8e8rJuMmhqfAdoB60Vk\nEnYsRTlsk+ntgCtgWCIih7HjQI5gT4iP4vStO0HMARGZgw3KzmEHsbUE/uljNXyJbfl51dneXLdO\ndsfe9ZPdfvWMfIUdQLgAu03Uxm6DW7GDT3PiWWe+P4p9LsG12KBnS07m6YxfykpLx1fAAyJyBvt9\ntca2Rh33yLcJe6J6WuwzOi5hB1J75vNJ7DM3umLvGjrkpD0GTBeRvxljPAfZZtdW7PiAt8U+K+Ic\ndlsv4yXvY9hj7EaxzxzYi/0uOxtjXCfNaOz2/pqIzMbuPwuMMTEiEontPrsWO8CvNTAQmGWM+TG7\nFXfG/bwL/AoYERngkWWuMeaU2AewPSv2mRS/Y7vyapB+v8yo7t5aGV/D3ma5RERct04OAaqSfuC0\n37oafMrt2yv89cI2jX2IPalcxPYN/og9IBRzyxeAvYd1N3bw1F7siNiiHvOLBRZ6KScZeMcjraaT\nPtot7ROnDmHYk8NZ7Ib3QgbzfMHt/YtOWjmPfIOd9Boe6T2wO+UZ57UVe5993UzWmWt+Gb2qOPlC\nsU2urgE/m4AHvMyvHPZ5FKewzbOfYAO2FOBej+VLcnvfDttKst+Z/35nPnU85n8Xdke/hNvtmE45\nezzyCvbEt9WZ52Hsgbt5JuvkE+w95d4+q4VtFfK8VW0oNlA65yz7Jmx/bkWP+rwEHHTyLcMOQj0G\nvO/lO/F6O6vzXYzHbrcJzvyWAA+55RmGPakfxba67cQerIKdz4tin/sQ49T3jPP/CC/rwnO9BmGf\nT7LfKX87btu9r/3Ebb+anIX9+Wkn7wXsXRB3etYHL/tdRvuU236yxZnnr9hbQdMtYwb1+Q7YnEme\ntk657rdOluHPfec0Nvip5209YFsCdjnbWOrtitiTc7pjkef6xJ54TgLzveSb63zPNX3UP8P16ZGv\nEbDUmd9h7B1PzZxp+3vkbYLdt12DIbd6+V5ecLany6Q97hTBttrtcba1OOxzRzxvq43Hnui91TUe\nmOj873oEc2bHu6rO+jrh1DsS+wyJZGz3RFbqnlquW97a2K7BE9iLnR+xgZN7ng7OfO72SHfVvb+3\n5cyPlzgVUSpPiH1K3lzgVmPMWn/XpyBxrvBPAs8ZY7L7WxlKKZVvsj1mQUTaiH306EGxj6W8O5P8\nlUQkUuwv9yWLSGbN4qqQEo9HUYtIALYp0nXletXyXDcOVz/o9/lbG6WUyp6cjFkohW1mnYxtXspM\ncWxz6CvYg6O6cr3r9POtxX7vvbGPaH3WZO8+7yvR/SLyIHag0zns+Im+wLfa4qKUKuiyHSwYY77F\n9sG7RsFmln8fTpAgIkOzW54qVFZgxwl0w/4ewW7s45//6qCqK8Ev2H7NJ7H92Eew996n+2ExpZQq\naAr93RCq4DD2Z52jMs14FTLGbMQ+/EgppQqdK+E5C0oppZTKQwWyZcG5r/YO/rw9TCmllFJZUwJ7\n2/5ikwvP9IECGixgA4VIf1dCKaWUKsQGYB9N/pcV1GBhL8D06dNp1KhRJllVbhk9ejRvveX5i7Aq\nL+k6z3+6zvOfrvP8tW3bNgYOHAi58xtEQA6CBREphf1BHNedELVFpBlwwhizX0Rewz7FarDbNM2c\n/MFAeed9ojFmG94lADRq1Ijw8Jz+fLjKrpCQEF3f+UzXef7TdZ7/dJ37Ta514+ekZaEl9tGnxnmN\nc9KnYR9XWgmo7jHNRv58/n049id99+H952aVUkopVYDk5DkLK/FxF4UxZoiXNL3rQimllCqk9CSu\nlFJKKZ80WFCp+vXr5+8qXHV0nec/Xef5T9d54Vcgf3VSRMKB6OjoaB0Uo5S66sTHx3P8+HF/V0MV\nUKGhodSoUSPDz2NiYoiIiACIMMbkyo/4FdRbJ5VS6qoUHx9Po0aNuHDhgr+rogqooKAgtm3b5jNg\nyG0aLCilVAFy/PhxLly4oM+ZUV65nqFw/PhxDRaUUupqp8+ZUQWJDnBUSimllE8aLCillFLKJw0W\nlFJKKeWTBgtKKaWU8kmDBaWUUkr5pMGCUkopv5gwYQIBAQG0bt3a31VRmdBgQSmllF/MmDGDWrVq\nsWHDBmJjY/1dHeWDBgtKKaXyXVxcHGvWrOHNN98kNDSUyMhIf1fJK32SpqXBglJKqXwXGRlJuXLl\n6NatG3369PEaLBhjeOedd2jatCklS5akQoUK3HnnncTEpP25g+nTp3PjjTdSqlQpypUrR9u2bVm6\ndGnq5wEBAbz88svp5h8WFsZDDz2U+n7atGkEBASwatUqRo4cScWKFalevTpgH8M9cuRIGjZsSFBQ\nEKGhodx3333s27cv3XxPnz7N6NGjqVWrFiVKlKB69eoMHjyYEydOcP78eYKDgxk9enS66Q4ePEhg\nYCCvv/561ldkPtEnOCqllMp3M2bMoHfv3gQGBtKvXz8+/PBDoqOjXT+ABMBDDz3EtGnT6NatG8OH\nDycpKYnVq1ezbt261Kdbjh07lrFjx3LLLbfwyiuvUKxYMdavX893331Hp06dfNZBRLymjxw5kgoV\nKvDiiy9y/vx5AH766SfWrVtHv379qFatGnv37mXChAm0b9+e3377jRIlSgBw/vx5br31Vnbs2MHQ\noUNp0aIFx48f54svvuDAgQM0bdqUnj17MnPmTN588800dZgxYwYAAwcOzPmKzSvGmAL3AsIBEx0d\nbZRS6moSHR1trvTj388//2xExKxYsSI1rXr16mb06NGp71esWGFEJE2ap927d5siRYqYPn36+CxP\nRMzYsWPTpYeFhZkhQ4akvp86daoREdO2bVuTkpKSJm9CQkK66devX29ExEyfPj01bcyYMSYgIMAs\nXLgww/osWbLEBAQEmMWLF6dJb9asmWnfvr3PZcnK9uHKA4SbXDova8uCUkoVYhcuwPbteVtGw4YQ\nFJR784uMjKRSpUq0a9cuNe3+++8nMjKScePGISLMnTuXgIAAxowZk+F85s+fjzHGZ57sEhGGDx+e\nrtWhePHiqf8nJSVx5swZateuTdmyZYmJiWHAgAEAzJs3j2bNmnH33XdnWEbHjh2pXLkykZGRdO7c\nGYAtW7bwyy+/MHny5FxbltykwYJSShVi27eDW8t9noiOhtz6TauUlBRmzpxJ+/bt09wB0apVK8aN\nG8fy5cvp2LEjsbGxVKlShbJly2Y4r9jYWAICAnL91znDwsLSpSUkJPDf//6XqVOncvDgQVcrOCLC\n6dOnU/Pt2bOHPn36+Jy/iDBgwAA+/PBDEhISKFGiBJGRkZQsWTLTaf1FgwWllCrEGja0J/O8LiO3\nrFixgkOHDvH5558TFRWV5jMRITIyko4dO+ZegT4kJyd7TS9ZsmS6tFGjRjFt2jRGjx7NTTfdREhI\nCCLC/fffT0pKSrbLHjRoEP/73/9YsGABffv2JSoqiu7du1O6dOlszys/aLCglFKFWFBQ7l3154fp\n06dTsWJFJkyYkHp17jJ37lzmz5/Phx9+SJ06dViyZAmnTp3KsHWhTp06pKSk8Ntvv9G0adMMy7zm\nmms4depUmrTLly9z6NChLNd77ty5PPjgg7zxxhupaZcuXUo33zp16rBly5ZM59ekSRNatGhBZGQk\nVatWJT4+nvfffz/L9clveuukUkqpfJGQkMD8+fPp3r07PXv2pFevXmleo0aN4syZM3zxxRf07t2b\nlJQUxo4dm+H8evTogYjw8ssvpws83NWpU4dVq1alSZs4cWKGLQveFClSJF0Lwvjx49PNo3fv3mze\nvJmFCxdmOs8HHniAxYsX8/bbbxMaGkqXLl2yXJ/8pi0LSiml8sXChQs5e/ZshoP/brrpJsqXL09k\nZCQLFizggQceYPz48ezcuZMuXbqQkpLC6tWruf322xk5ciR16tThueee4z//+Q9t2rShV69eFC9e\nnJ9++omqVavy6quvAjBs2DAeeeQR+vTpQ6dOndi8eTNLliyhfPny6eqQUdBx11138dlnn1GmTBka\nN27M2rVrWb58OaGhoWnyPfnkk8yZM4d7772XIUOGEBERwR9//MGXX37JxIkTuf7661Pz9u/fn6ee\neooFCxYwcuRIihQpktNVm+cKdLBwOfmyv6uglFIql8yYMYOgoKAMxySICN26dWPGjBmcPHmSqVOn\n0qxZMyZPnsxTTz1FSEgILVu25Oabb06dZuzYsdSuXZt3332X559/nqCgIJo2bcqgQYNS8wwfPpy9\ne/cyefJkFi9ezG233cbSpUvp0KFDurseMnr2wvjx4wkMDGTGjBkkJCRw6623smzZMu64444005Qq\nVYoffviBF198kfnz5/Ppp59SoUIFOnbsSLVq1dLMs0KFCnTu3JlvvvmmYD5bwY34arrxFxEJB6LD\nng7jk0c+oV1YO39XSSml8kVMTAwRERFER0enPnhIXbl69erFli1b2LlzZ5byZ2X7cOUBIowxMV4z\nZVOBHrNQpngZ2k9rz8B5Azl87rC/q6OUUkrlmkOHDvH111+naQUpqAp0sDD57slMuXsKi/cspsF7\nDRi/fjxJKUn+rpZSSimVY3v37mX69On069ePYsWKMWLECH9XKVMFOlgIkACGtBjCjlE76H9df/7x\n7T+4YdINrN2/1t9VU0oppXJk5cqVDBo0iPj4+NQxDQVdgQ4WXMqVLMcHd33A+mHrKSJFuHnKzQz7\nYhjHLxz3d9WUUkqpbBk8eDApKSnExsbSs2dPf1cnSwpFsOByQ9UbWD9sPRO6TmDutrnUf7c+7294\nX7smlFJKqTxUqIIFgCIBRfjbDX9j56id9G7Um8e+eYyWH7Vk9b7V/q6aUkopdUUqdMGCS/lS5Zl0\n9yTWD1tP8cDi3Db1NgbMG8DvZ3/3d9WUUkqpK0qhDRZcbqh6A2uHrmXK3VNYumcpDd5rwBs/vkFi\ncqK/q6aUUkpdEbIdLIhIGxH5QkQOikiKiGT8o91/TtNORKJFJEFEdorI4JxV1zvXXRM7H9vJ0BZD\n+ffyf3P9B9ezePfi3CxGKaWUuirlpGWhFLAJGAlk+vhHEQkDvgKWA82Ad4CPRaRTDsr2qWyJsrzd\n5W02PbJ8XBlVAAAgAElEQVSJKqWr0CWyCz0+78HuE7tzuyillFLqqpHtYMEY860xZowxZiHg/SHa\naf0NiDXGPGWM2WGMeR+YA4zObtlZdV2F61gxaAUz+8wk5lAMTSY04emlT3Pm0pm8KlIppZS6YuXH\nmIWbgGUeaYuB1nlZqIhwX5P72D5qO8+1eY53N7xL/XfrMzlmMskpWf9ZUqWUUupqlx/BQiXgiEfa\nEaCMiBTP68KDigYxpu0YdozaQYfaHRj25TBafdxKb7VUSik/mDZtGgEBAamvokWLUq1aNYYMGcLv\nv6e9m61du3YEBATQoEEDr/NatmxZ6nzmzZuX5rNff/2VPn36EBYWRsmSJalWrRqdO3fmvffeS5Mv\nLCwsTX3cX127ds3dhS/ECvRPVOem6iHViewVyaM3PMrj3z7ObVNv474m9/FGxzeoWbamv6unlFJX\nDRHhlVdeISwsjISEBNatW8cnn3zCjz/+yJYtWyhWrFhqvpIlS7J7925+/vlnWrZsmWY+kZGRlCxZ\nkoSEhDTpa9as4fbbb6dmzZqMGDGCSpUqsX//ftatW8f48eMZNWpUmrq0aNGCJ554As9fYa5SpUoe\nrYHCJz+ChcNARY+0isAZY8wlXxOOHj2akJCQNGn9+vWjX79+Oa7MzdVvZv2w9Xy2+TOeXf4sDd9v\nyBOtn+DpW58muFhwjuerlFIq67p06ZL6E8sPPfQQ1157LW+88QZffPEFffr0Sc1Xp04dkpKSiIqK\nShMsXLp0ifnz59OtWzfmzp2bZt6vvvoqZcuW5eeff6Z06dJpPjt+PP3PBFStWvUvnVf8KSoqiqio\nqDRpp0+fzvVy8iNYWAvc6ZHW2Un36a233sqT33MPkAAGNx9M78a9eW31a/xvzf+YvHEyr7R/hQeb\nP0iRgCK5XqZSSqmMtWnThtdff509e/ak+6xfv35MnDiRcePGpaZ98cUXXLx4kfvuu485c+akyR8b\nG0uTJk3SBQoAoaGhuV95P/J2AR0TE0NERESulpOT5yyUEpFmItLcSartvK/ufP6aiExzm+RDJ8/r\nItJAREYCfYA3/3Lt/6LgYsG82uFVto/aTtuwtgz7chjhH4WzdM9Sf1dNKaWuKnFxcQBcc8016T7r\n378/v//+O99//31qWlRUFB06dKB8+fLp8tesWZPo6Gi2bt2apbIvX77MH3/8ke7l2b1xNcvJAMeW\nwEYgGvuchXFADDDW+bwSUN2V2RizF+gGdMQ+n2E0MNQY43mHhN+ElQ0jqncU64auo3Sx0nSe3pmu\nkV3ZejRrG5pSSqnsOX36NH/88QcHDx5k7ty5vPzyy5QsWZK77rorXd46derQsmVLZsyYkTrtokWL\nGDBggNd5P/HEE1y4cIHmzZtzyy238Mwzz7B06VKSkrz/6ODixYspX758mleFChUYP3587i1wIZft\nbghjzEp8BBnGmCFe0lYBudsmkgdurHYjq4esZt62eTy97GmaftiU4eHDGdtuLBWDPYddKKWU/124\nfIHtx7fnaRkNQxsSVDQo1+ZnjKFDhw5p0mrVqsWMGTMyHFTYv39//vOf/zBhwgRmz55NYGAgPXr0\n4Oeff06Xt2PHjqxdu5bXXnuNxYsXs27dOt544w3Kly/Pxx9/TPfu3dPkv+mmm3j11VfTDXCsV6/e\nX1zSK8dVczdEVokIvRv3pnuD7ry/4X1eWfUKM36dwTO3PsPom0ZTsmhJf1dRKaVSbT++nYiP8vZa\nLHpENOGVc2/8mIgwYcIE6tWrx+nTp5kyZQqrVq1KvQvCm759+/Lkk0+yaNEiZsyYwV133UWpUqUy\nzB8REcGcOXNISkpi8+bNzJ8/n7feeot7772XTZs20bBhw9S8oaGhtG/fPteW70qkwUIGihUpxujW\noxncfDCvrHyFl75/iQ9+/oCX273MoGaDdBCkUqpAaBjakOgR0XleRm674YYbUgew33PPPdx66630\n79+fHTt2EBSUvhWjUqVKtG3blnHjxrFmzZp0z1XISGBgIBEREURERFCvXj2GDBnC7NmzeeGFF3J1\nea50GixkolzJcrzV5S1GtRrFcyue46EvHmLc2nH8v47/j271uiGSlSdeK6VU3ggqGpSrV/3+EBAQ\nwGuvvUb79u157733eOqpp7zm69+/P8OGDaNcuXLceafnTXaZc916eejQob9U36tRof+J6vxSp1wd\nPu/zORuGbaBCqQp0j+pOu2ntWHdgnb+rppRShV7btm1p1aoVb7/9NomJiV7z9OnTh5deeon333+f\nwMCMr3Xd75pw9/XXXwNk+ETIK0WKScn1eWrLQjbdUPUGlg9azuI9i3l62dO0ntya3o168+rtr9Ig\n9MreAJVSKjd4DiR0efLJJ7n33nuZOnUqI0aMSPd5mTJlGDNmTKbzf+yxx7hw4QI9e/akYcOGJCYm\n8uOPPzJr1ixq167NkCFpx+EfPHiQyMjIdPMJDg7mnnvuyeJS+Z8xhi93fsk/5/wz1+etwUIOiAhd\n6nahU+1ORP4ayQvfvUCTCU0YHj6cMW3HULl0ZX9XUSmlCqyMum979epFnTp1GDduHMOHD/eZ19f8\nxo0bx+zZs/nmm2+YNGkSiYmJ1KhRg1GjRvHcc89RpkyZNPk3bdrEoEGD0s23Zs2ahSZYWLl3Jc8u\nf5a1B9bSskTLzCfIJskowvMnEQkHoqOjo/PkCY65LSEpgfc3vM+rq1/lUvIlHr/xcZ68+UmuKZn+\n4SJKKeWL6+l7heX4p/KX5/ax8dBG/r3i33y7+1siKkfwWofXKHeqnGt8RoQxJiY3ytUxC7mgRGAJ\n/nXzv9jz9z3848Z/8M76d6j1Ti3+u/q/nEs85+/qKaWUusLEn4qn75y+hH8UTuzJWGbfO5ufhv9E\npzqd8mTgvQYLueiaktfwaodXif17LIObDWbsyrHUGV+H8evHcynJ529mKaWUUlnWe1Zvfoj/gUnd\nJ7F15Fb6NO6Tp3fnabCQByoGV+SdO99h56id3FXvLkYvHk399+ozZeMUklK8P25UKaWUyqq/3/h3\ndj22i2HhwwgMyPvhhxos5KGaZWsy+Z7JbB25lZuq3cTQL4bSZEITZm2dlSe3tiillLo6PNDsgXx9\norAGC/mgYWhDZvaZScyIGOqWq8v9c+6n+YfNmbdtngYNSimlCjwNFvJRi8ot+Lr/1/z40I9UDK5I\n71m9CZ8YzoLtCzK871gppZTyNw0W/ODm6jez9IGlrHpwFeVKlqPnzJ60nNSSL3d8qUGDUkqpAkeD\nBT9qU7MNKwav4LvB3xFcLJi7P7+bVh+3YtGuRRo0KKWUKjD0CY4FQLuwdnw/+Hu+2/sdY74bQ7cZ\n3bix6o2MaTuGO+veqT9WpdRVaNu2bf6ugiqA/LVdaLBQQIgIt9e6nfZh7VkWu4wXv3+RbjO6EVE5\ngudve567G9xNgGhDkFJXutDQUIKCghg4cKC/q6IKqKCgIEJDQ/O1TA0WChgRoVOdTnSs3ZEVcSt4\nZdUr9JzZk+sqXMfzbZ6nT+M+FAko4u9qKqXySI0aNdi2bRvHjx/3d1VULjp76SxRW6KI/DWShKQE\nejXsxeBmg6lUulK25xUaGkqNGjXyoJYZ02ChgBIROtTuQIfaHVi9bzWvrn6VvnP70uD7Bvy7zb/p\nf33/fHkQh1Iq/9WoUSPfTwYqbxy/cJzx68fzzvp3SExO5OGuD/PkzU9StUxVf1ctW7RduxBoU7MN\n3w78lvXD1tMgtAGDFwym/rv1mRQ9icRk77/7rpRSyn/2n97PP779BzXfrsm4teMY1mIYcY/H8XaX\ntwtdoAAaLBQqraq2YmHfhWx8eCMRVSJ4+KuHqf1Obd5c+yZnL531d/WUUuqqt/OPnQxdOJQ64+sw\nbfM0/tX6X+z7xz7G3TGOSsHZ73IoKDRYKISaV2rO7Htns2XkFjrW7sjTy56m5ts1eWHFCxw7f8zf\n1VNKqatOzKEY7p19Lw3fa8g3u7/hvx3+S/w/4nm5/cuEBuXvYMS8oMFCIda4fGOm9pia+iuXb617\ni5pv12TUolHEnYzzd/WUUuqKZoxh5d6VdJnehYiPIth4aCMf3vUhsY/H8sTNT1C6eGl/VzHXaLBw\nBageUp23urxF/Oh4nr31WT7f8jn13q3HgHkD+OXIL/6unlJKXVGSUpKYvXU2N02+iXbT2nHo3CGi\nekexfdR2RkSMoERgCX9XMddpsHAFKVeyHC+0fYH40fG83eVtfoz/kWYfNqNrZFdWxK3Qp0IqpdRf\ncC7xHO+uf5f679bnvjn3EVwsmK/7f82mhzfR97q+V/QdahosXIGCigYxqtUodj22i+k9p3Pw7EE6\nfNqBFhNb8OnmT/UOCqWUyoZDZw/x3PLnqPFWDUYvHk3r6q2JHhHN8kHL6Vqv61XxlF0NFq5gRYsU\nZUDTAWx6eBPLHlhG1TJVGbxgMGFvh/Ha6tc4cfGEv6uolFIF1m/HfmPowqGEvRPG+A3jGdJ8CLGP\nxxLZK5LwyuH+rl6+unLbTFQq9wc8/XbsN95e9zZjV47lP6v/w5DmQ3j8xsepd209f1dTKaX8LsWk\nsGTPEt5Z/w7f7v6WKqWr8Er7VxgRMYKyJcr6u3p+oy0LV5nG5RvzUfePiB8dz1M3P8WsrbNo8F4D\nenzeg+/ivtNxDUqpq9K5xHNM+GkCjd9vzJ2Rd3Lk3BGm9ZhG3ONxPHXLU1d1oAAaLFy1KpSqwIvt\nXiR+dDwfdf+IXSd2cfunt9P0w6ZM/Hki5xPP+7uKSimV5+JOxvHEkieo9mY1HvvmMa6veD2rh6wm\nekQ0g5oNoliRYv6uYoGgwcJVrkRgCYaFD2PL37aw7IFl1LmmDiMXjaTaW9X41+J/EXsy1t9VVEqp\nXGWM4fu939NzZk/qvluXKRun8HDEw8Q9Hsfse2dza41br4pBi9mhYxYUkHZcw95Te/ngpw/4eOPH\nvLXuLbrV78ZjrR6jU+1OugMppQqts5fOEvlrJB/8/AG/HPmFxuUbM6HrBAY2HUipYqX8Xb0CTVsW\nVDphZcN4vdPr7B+9n0ndJ7H/9H7umH4Hjd5vxLvr3+VUwil/V1EppbJsy9EtPPr1o1R9syqPLnqU\nWmVrsfSBpWz52xYebvmwBgpZIAVxQJuIhAPR0dHRhIdfXbenFETGGH6I/4F3N7zL/O3zKRpQlL7X\n9eXhiIdpVbWVtjYopQqcS0mXmLdtHhN+nsAP8T9QKbgSw8OHMzx8ONVDqvu7enkqJiaGiIgIgAhj\nTExuzDNH3RAi8ijwBFAJ2Aw8Zoz5KZP8jwJhwD7gv8aYz3JStsp/IkKbmm1oU7MNh88dZsrGKXwU\n/RGfbPqEZhWb8UjLRxhw/YAr6jnoSqnCae+pvXwU/REfx3zMsQvHaBfWjll9ZtGjYQ+KFinq7+oV\nWtluWRCR+4FpwAhgAzAauBeob4w57iX/34DXgGHAz8CNwCSgnzHm6wzK0JaFAi45JZkle5YwMXoi\nX+78kpKBJRlw/QAebvnwVfewEqWUfyUmJ/LFji/4OOZjluxZQunipRncbDCPtHyExuUb+7t6+S4v\nWhZyEiysA9YbYx533guwHxhvjHnDS/4fgR+MMU+7pf0f0MoYc1sGZWiwUIgcOHOAyTGTmRQziYNn\nD9KySkuGthhK3+v6XvX3Jiul8s5vx35jcsxkPv3lU45fOE7raq1Tjz1X8ziEvAgWsjXAUUSKAhHA\ncleasdHGMqB1BpMVBxI80hKAViJSJDvlq4KpWplqvNjuRfb+Yy8L+y6kYqmKPLroUSqPq8zAeQNZ\nEbeCFJPi72oqpa4A5xLPMWXjFG6ZcgtNJjRh2uZpDGo6iK0jt7Jm6BqGhg+9qgOFvJLdMQuhQBHg\niEf6EaBBBtMsBoaJyEJjTIyItASGAkWd+XnOSxVSgQGB3N3gbu5ucDe/n/2dzzZ/xpRNU4j8NZKw\nsmEMaT6Ewc0GU7NsTX9XVSlViBhjWHdgHZ9s+oSoLVGcTzxPpzqdmNVnFnc3uJvigcX9XcUrXra6\nIUSkMnAQaG2MWe+W/jpwmzEmXeuCiJQA3gMewLZkHAamA08BlYwxx7xMEw5E33bbbYSEhKT5rF+/\nfvTr1y/LdVb+ZYxh7YG1TNk4hZlbZ3I+8TwdanfgoeYP0aNhD0oWLenvKiqlCqi4k3FM/2U6n/7y\nKbtP7KZ6meo81OIhhjQfohcdjqioKKKiotKknT59mlWrVoG/xiw43RAXgN7GmC/c0qcCIcaYnj6m\nLQJUBA4BDwP/zxjjtUNbxyxcmc4lnmPOb3OYsnEKq+NXU7pYaXo37s3A6wfSLqwdRQK0V0qpq93p\nhNPM+W0On/7yKav2raJU0VL0adyHQc0G0S6sHQGijwfKjN9vnTTGXBaRaKAD8AWkDnDsAIzPZNpk\n4Hdnmr7AlzmpsCq8gosF82DzB3mw+YPsPrGbGb/O4LNfPmPqpqlUKV2F/tf1Z2DTgTSt2FSf3aDU\nVSQpJYmle5by6S+fsmD7Ai4lXaJj7Y581vMzejbsqWMQCoCc3A1xHzAVeIQ/b53sAzQ0xhwTkdeA\nKsaYwU7+ekArYD1QDvgnNriIMMbEZ1CGtixcJYwxbDi4gem/TOfzrZ9z/MJxrqtwHQOvH0j/6/tf\n8Q9PUepqlWJSWLN/DZ9v+ZzZv83m6PmjNC7fmMHNBtP/+v5UK1PN31UstPzesgBgjJklIqHAy9hu\nhU3AHW5jDyoB7kf4IsC/gPrAZeA74OaMAgV1dRERbqx2IzdWu5E373iTJXuWMP3X6by08iWeWf4M\nbWq04b4m99GncR8qBVfyd3WVUn+BMYaYQzFEbYli5taZHDhzgGplqvFA0wfod10/wiuHa6tiAaWP\ne1YF0plLZ5i/bT4zt85kaexSklOSaRvWlvsa30evRr2oGFzR31VUSmXR1qNb+XzL53y+9XN2n9hN\n+aDy3Nv4Xvpe15dbatyi4xByWYF4KFN+0GBBuTtx8QQLti9g1tZZLItdhsHQLqxdauBQvlR5f1dR\nKeXGGMMvR35h3rZ5zN02l63HthJSPITejXrT97q+tK/VnsAA/dHjvKLBgrrqHb9wnAXbFzBz60xW\nxK1AENqFtaNnw57c0/Ae7edUyk9STArrD6xn3rZ5zNs+j9iTsYQUD+Gu+ndxX5P7uKPOHfo8hHyi\nwYJSbo6dP5Z6YFoRt4KklCRaVmlJjwY96NGwB43LN9b+T6XyUFJKEqv2rWLetnnM3z6f38/+ToVS\nFejRoAe9GvWifa32FCtSzN/VvOposKBUBk4lnOKbXd+wYMcCFu1axLnEc9QtV5ceDXpwT8N7aF2t\ntT7HQalccCrhFEv2LOGrnV/x9a6vOXHxBDVCatCrYS96NerFzdVv1n3NzzRYUCoLLiVdYkXcChZs\nX8DCHQs5cv4I5YPKc2e9O+latyud63TmmpLX+LuaShUKxhh2/rGTr3Z+xVe7vmL1vtUkm2SaVmzK\nXfXuomejnkRUjtBWvAJEgwWlssnVj7pwx0IW7VrEr0d/JUACaF2tNV3rdaVrva40q9hMD3RKuUlM\nTmT1vtWpAcLuE7spEViCDrU60K1eN7rV70aNkBr+rqbKgAYLSv1FB84c4Jtd37Bo9yKWxS7jXOI5\nKgdX5s66d9K1Xlc61O6gP6utrjrGGLYf386SPUtYGruU7/d+z/nL56lauip31b+Lu+rfxe21bieo\naJC/q6qyQIMFpXJRYnIiP8T/wKJdi1i0axHbjm8jQAJoWaUlHWp1oGPtjtxc/WZKBJbwd1WVynXH\nzh9jedzy1ADhwJkDFCtSjFtr3Ern2p25o+4d2upWSGmwoFQe2ntqL8til7E8bjnLY5dz7MIxSgSW\n4Jbqt9Cxdkc61OpAeOVwHbylCqUzl87wY/yPfL/3e5bFLSPmkD2HXFfhOjrX7kynOp24reZt2npw\nBdBgQal8kmJS2HJ0S2rwsHLvSs5fPk/ZEmVpW7MtbWq0oU3NNrSo1IKiRYr6u7pKpXMq4RSr961m\n5b6VrNy3kphDMaSYFCoFV6JDrQ50rtOZjrU7UqV0FX9XVeWyAvHbEEpdDQIkgKYVm9K0YlP+2fqf\nJCYnsuHgBpbFLmPlvpU8/93zJCQlEFQ0iNbVWqcGDzdWvVF/IU/5xdHzR1mzfw0r99rgYNPhTRgM\n1cpUo23NtowIH0HbsLbUK1dPuxZUtmnLglI5kJicSPTv0ayOX80P8T/wQ/wPnEw4SWBAIOGVw2lT\nwwYOraq2okZIDT04q1x1Ofkym49sZt2Bdaw9sJa1+9cSdyoOgJohNWkb1pa2NdvSLqwdtcrW0u3v\nKqPdEEoVUCkmhd+O/cbqfatZHb+aH/f/SPxp+8OqFUtVpFXVVqmvG6rcoM95UFlmjOHg2YP8dPAn\n1h5Yy7oD6/j595+5mHSRogFFCa8czk3VbqJ1tda0rt5ab2lUGiwoVZgcPneYnw7+xIaDG1h/cD0b\nDm7g9KXTANS/tj6tqrYivFI4zSs1p1mlZpQrWc7PNVb+Zowh7lQcMYdi0ryOXTgGQLUy1WhdrXVq\ncNCicgu9W0elo2MWlCpEKgVXonuD7nRv0B2wrQ+7T+xm/QEbOGz4fQNzfptDQlICANXLVKdZpWY0\nr9g8NYCofU1t/fneK9TFyxfZdnwbW49uZdPhTWw8vJGYQzGpAWXV0lUJrxzOyBtGEl45nPDK4fpD\nacpvNFhQKp8ESAD1r61P/Wvr80CzBwD7Qzy7/tjF5iOb2XR4E5sOb+LjjR9z+NxhAIKLBdOkfBMa\nlW9Eo1DnVb4RtcrW0ls4C4mEpAR2HN/B1mNb2XJ0C1uPbWXr0a3EnozFYFt2w8qGEVE5gqdueYrw\nyuG0qNSCisEV/Vxzpf6kwYJSfhQYEGgDgfKN6Htd39T0w+cOs/mwDSBcJ5k5v83hXOI5AIoXKU79\na+vTMLQhjUIb0TC0IXXK1aFW2VqEBoXqgLZ8lpSSxL5T+9h9Yje7Tuxi94nd7D6xm51/7GTPyT2k\nmBTAthY0qdCEuxvcTZPyTWhSoQmNyzemTPEyfl4CpXzTYEGpAqhScCUq1a3EHXXvSE1zDXTbdmwb\n245vS/27at8qjpw/kpovuFgwta+pbV9la6f+X+uaWlQvU11v7cyB5JRkjpw/QvzpePaf3s/+M/vZ\ne2pvalAQdyqOpJQkAIoGFKX2NbWpW64uXet1pXH5xqmBgT5KXBVWGiwoVUiICNXKVKNamWp0qtMp\nzWenE04TdyqO2JOxaV5f7vySvaf2cjnlcmrekOIhVCldhaplqlK1tPMq8+ffSsGVuLbktZQsWjK/\nFzHfpZgUTl48yZHzRzh6/ihHzx/lyLkj/H72d+LP/BkYHDhzIDUYAChVtBQ1QmpQt1xdutfvTt1y\ndalbri71rq1H9TLVtYtIXXE0WFDqChBSIoTmlezASE/JKckcPHuQuJNxHDhzgINnD3LwzEEOnj3I\njj92sCJuBYfOHUpzMgR7QgwNCvX6KleyHKWLlSa4WDCli5emdLHS6f7mxwnTGMOl5EtcvHyRC5cv\ncPrSaU4nnOb0pdOcSjjF6QTnr5N+6tIpjp0/ZoOC80c4dv4YySY5zTyLFSlG5eDK1AipQfWQ6txS\n/Raqh1S378tUp3pIda4pcY129airigYLSl3higQUoUZIDZ/336eYFI6eP8rBMwc5duEYxy8cT30d\nO3+M4xePs//MfjYe3sjxC8c5cfFEuuDCU4nAEhQvUpxiRYqlvooWKZr2fUBRRARjDAaT+jfFpKRJ\nS0pJ4mLSRRKSElJfFy9f5FLyJZ91CJAAQoqHEFIiJPVvhVIVqFeuHhVKVaBCqQpUDK745/+lKlKm\neBkNBJTyoMGCUooACbDjJIIrZSm/64r+XOI5zl46y9nEs+n+nks8R2JyYurrcvLlNO8TkxNJTEnE\nGIOIECABCGL/JwARSX0fGBBIycCSlAgsQcmi9q/r5Z7uCgjKlihLSPEQgosF64lfqVygwYJSKttE\nJPVkHRoU6u/qKKXymD7tRSmllFI+abCglFJKKZ80WFBKKaWUTxosKKWUUsonDRaUUkop5ZMGC0op\npZTySYMFpZRSSvmkwYJSSimlfNJgQSmllFI+abCglFJKKZ9yFCyIyKMiEiciF0VknYjckEn+ASKy\nSUTOi8jvIjJZRMrlrMpKKaWUyk/ZDhZE5H5gHPAi0ALYDCwWEa8PiBeRW4BpwCSgMdAHaAV8lMM6\nK6WUUiof5aRlYTQw0RjzqTFmO/AIcAF4KIP8NwFxxpj3jTH7jDFrgInYgEEppZRSBVy2ggURKQpE\nAMtdacYYAywDWmcw2Vqguojc6cyjInAv8HVOKqyUUkqp/JXdloVQoAhwxCP9CFDJ2wROS8JAYKaI\nJAKHgJPAqGyWrZRSSik/CMzrAkSkMfAO8BKwBKgM/B+2K2KYr2lHjx5NSEhImrR+/frRr1+/PKmr\nUkopVZhERUURFRWVJu306dO5Xo7YXoQsZrbdEBeA3saYL9zSpwIhxpieXqb5FChhjLnPLe0WYDVQ\n2Rjj2UqBiIQD0dHR0YSHh2djcZRSSqmrW0xMDBEREQARxpiY3JhntrohjDGXgWiggytNRMR5vyaD\nyYKAJI+0FMAAkp3ylVJKKZX/cnI3xJvAcBEZJCINgQ+xAcFUABF5TUSmueX/EugtIo+ISC2nVeEd\nYL0x5vBfq75SSiml8lq2xywYY2Y5z1R4GagIbALuMMYcc7JUAqq75Z8mIsHAo9ixCqewd1M88xfr\nrpRSSql8kKMBjsaYCcCEDD4b4iXtfeD9nJSllFJKKf/S34ZQSimllE8aLCillFLKJw0WlFJKKeWT\nBgtKKaWU8kmDBaWUUkr5pMGCUkoppXzSYEEppZRSPmmwoJRSSimfNFhQSimllE8aLCillFLKJw0W\nlFJKKeWTBgtKKaWU8kmDBaWUUkr5pMGCUkoppXzSYEEppZRSPmmwoJRSSimfNFhQSimllE8aLCil\nlPf2zLMAABywSURBVFLKJw0WlFJKKeWTBgtKKaWU8kmDBaWUUkr5pMGCUkoppXzSYEEppZRSPmmw\noJRSSimfNFhQSimllE8aLCillFLKJw0WlFJKKeWTBgtKKaWU8kmDBaWUUkr5pMGCUkoppXzSYEEp\npZRSPmmwoJRSSimfNFhQSimllE85ChZE5FERiRORiyKyTkRu8JH3ExFJEZFk56/r9WvOq62UUkqp\n/JLtYEFE7gfGAS8CLYDNwGIRCc1gkr8DlYDKzt9qwAlgVk4qrJRSSqn8lZOWhdHARGPMp8aY7cAj\nwAXgIW+ZjTFnjTFHXS+gFVAWmJrDOiullFIqH2UrWBCRokAEsNyVZowxwDKgdRZn8xCwzBizPztl\nK6WUUso/stuyEAoUAY54pB/BdjH4JCKVgTuBSdksVymllFJ+kt93QzwInAQW5nO5SimllMqhwGzm\nPw4kAxU90isCh7Mw/RDgU2NMUlYKGz16NCEhIWnS+vXrR79+/bIyuVJKKXVFi4qKIioqKk3a6dOn\nc70csUMOsjGByDpgvTHmcee9APHAeGPM/3xM1w471uE6Y8y2TMoIB6Kjo6MJDw/PVv2UUkqpq1lM\nTAwREREAEcaYmNyYZ3ZbFgDeBKaKSDSwAXt3RBDO3Q0i8hpQxRgz2GO6odggw2egoJRSSqmCJdvB\ngjFmlvNMhZex3Q+bgDuMMcecLJWA6u7TiEgZoCf2mQtKKaWUKkRy0rKAMWYCMCGDz4Z4STsDBOek\nLKWUUkr5l/42hFJKKaV80mBBKaWUUj5psKCUUkopnzRYUEoppZRPGiwopZRSyicNFpRSSinlkwYL\nSimllPJJgwWllFJK+aTBglJKKaV80mBBKaWUUj5psKCUUkopnzRYUEoppZRPGiwopZRSyicNFpRS\nSinlkwYLSimllPJJgwWllFJK+aTBglJKKaV80mBBKaWUUj5psKCUUkopnzRYUEoppZRPgf6ugFJK\nKZUbkpPh0CE4cwbOn0//Onfuz/+Tk/1d27xz+HDuz1ODBaWUUoWCMXDiBMTF2VdsbNq/+/bB5csZ\nT1+sGAQHQ1AQFP3/7d15kJT1ncfx95dTOUQuYbjkUowHo4xREFEIEdRI1FwG3Ug0JutKLIIxq1Zi\nPBI1awxbJFkTN5uEWLWhclQZ5RBQAY0CojMCHgg4wsohhxzDMTCDzG//+HbbwzjTTDc9/Ux3f15V\nvxrn6efp/vXjMP2Z39k6e/XOtqqqzD+nwoKIiDQLIcDu3bBhg3/wb9jw6bJ3b+L8k06CgQNhwAC4\n+mr/euqp0LkztG//6dKqQD7xysqgpCSzz1kgt05ERJqDqioPAuXliRJvGdiwAfbtS5zbrp1/+Pfv\nDyNHwvXXeziIB4TOncEsqndSWBQWREQkY6qqYPNm2LgxUd5/PxEMNm70FgTwboEBA/zDf9QouPFG\nDwbxgNCtm8JAc6GwICIixxQCVFT4AMJ42bLFP/w3bUoEg23bjr6uc2cPA4MGwYUX+td46d0bWraM\n5v1IahQWREQK2JEj8NFH/uG/devRX+uWgwePvrZjR+jb18u558KECYnv+/aFPn18rIDkPoUFEZE8\nFIKHgM2bP13iH/5bt8L27Z+eRtilCxQVeRk40McL9OqVOBYvCgKFQ2FBRCTH1NT4h3ztcQHx7oBN\nmzwQbNkC1dWJa1q0gJ49vem/Vy/vEujZ00tRUeLrKadA27bRvTdpnhQWRESamX374IMP6i8bN3oY\nqB0E2rZNNPsPGAAXX+yhoE8f/9q7N/ToUThTByXz9KMjIpJlBw/6zIB16+C993zKYO1AsGdP4tyW\nLf3Dvl8/DwTDhx89LqBvX80akKansCAi0gT27/e1A957z0s8GKxb510FcR06JBYTuvhiDwW1S1GR\nWgQkevoRFBFJw/799a8wGC87dybO7dABTjsNBg+GESP8a/z7Hj3UKiDNX1phwcwmA3cCPYGVwO0h\nhNeSnN8GuA+4IXbNFuDBEMKMdF5fRCQbKio+3TIQ/+/t2xPntW6dWEjovPPg2msTiwspEEg+SDks\nmNl1wC+A7wDLganAfDM7PYTwUQOX/Q3oDtwElANFaHtsEWkmdu+GlSu9rFoFq1d7KNixI3FO166J\n1oBx43xRoQEDPBT07OmzDUTyVTotC1OBJ0IITwKY2a3AF4CbgUfrnmxmlwOjgIEhhPiwnQ/Sq66I\nSPqOHPGBhfFgEC8bN/rjbdvCWWd5ueIKDwbx0rlztHUXiVJKYcHMWgMlwMPxYyGEYGbPAyMauGwC\n8Dpwl5l9AzgAPAPcG0I4lFatRUSOYfduePNNbymItxi89RZUVvrjRUVQXOybExUXezn9dA0mFKlP\nqv8sugEtgTqrf7MNGNLANQPxloVDwDWx5/gN0AX4VoqvLyJylJoaH0OwYoUHgng4iLcWtGnjLQVD\nh8J113koGDoUunePtt4iuSQbGboFUANcH0LYD2BmdwB/M7PbQghVWaiDiOSBqip4+214441EWbkS\nDhzwx3v39jBwww0eCIYO9daC1q2jrbdIrks1LHwEHAF61DneA9jawDUfApvjQSFmNWBAH3zAY72m\nTp1Kp06djjo2ceJEJk6cmGK1RSTXVFZ6a0FpKZSVeTB4+234+GOfWTBkSGLmwXnn+UZGXbtGXWuR\n7Jo5cyYzZ8486lhFRUXGX8dCfGPxxl5gtgx4NYQwJfa94QMWfxlC+Hk9538b+E/glBBCZezY1cDf\ngQ71tSyY2TCgtLS0lGHDhqX4lkQk1xw4kAgG8bJ6tXcxtGkD55zjgSBehg7VJkYiDSkrK6OkpASg\nJIRQlonnTKcbYhoww8xKSUydbAfMADCzR4BeIYRJsfP/DPwI+KOZ3Y9PoXwU+L26IEQKT1WVdx28\n9hosXw6vvw7vvuvBoG1bDwKjRsH3vgclJT7eoE2bqGstUthSDgshhL+aWTfgQbz7YQUwPoQQn5Hc\nE+hb6/wDZnYZ8CvgNWAn8Bfg3uOsu4g0czU1sGZNIhgsX+4tCIcP+ziC4mK49FK4445EMND4ApHm\nJ60BjiGEx4HHG3jspnqOrQXGp/NaIpI7qqpg2TJYvBheeslbDfbu9cfOOAMuuABuvNG/FhdrK2SR\nXKEZxSKStqoqePVVDweLF8PSpXDoEJx8sncl3H23B4OSEj8mIrlJYUFEGu3QIe9KePFFDwdLlvix\nTp28O+Hhh2H0aB930LJl1LUVkUxRWBCRBu3Z44Hgn//08tprUF3t4eCSS+ChhzwcFBcrHIjkM4UF\nEfnE1q0+1iAeDlatghB8o6RRo+Cxx/zrOecoHIgUEoUFkQK2a5d3Jyxc6GX1aj8+eLCHgilT/Oug\nQdpiWaSQKSyIFJB9+7zFIB4OVqzwloPBg+Fzn4Mf/9jHHhQVRV1TEWlOFBZE8tiePfDKK9618NJL\nPubgyBHfQ2HsWG85GDMG+vWLuqYi0pwpLIjkka1bveUgPu4gPuagqMi7E775TW9BGDxY3Qoi0ngK\nCyI5bONGH3Pw4oseENat8+ODBvlshSlT/OvAgQoHIpI+hQWRHLJ5MyxalFgEqTy2Z+vZZ8Nll8FP\nfuItCL16RVlLEck3CgsizdiWLR4K4gHhvff8+NlnwxVX+HiDSy6Bbt2irKWI5DuFBZFmZPduDwUv\nvODl3Xf9+Flnwfjx8LOfeTjo3j3SaopIgVFYEInQgQPw8ss+jfGFF6CszAckDhrksxUeeMBXSDzl\nlKhrKiKFTGFBJIviuzIuWuRl6VLfrrmoyGcpTJ7sX089NeqaiogkKCyINKHqal/bIB4O4hsvde7s\nLQbTpnkLwhlnaLaCiDRfCgsiGRQCrFwJ8+d718LLL0NlJZx0UmJXxjFjfFfGFi2irq2ISOMoLIgc\np/374fnnYc4cmDvXZzC0b+9TGO+7z8PBeedBK/1rE5EcpV9fImlYu9aDwZw5vhhSdTUMGQJf/zpc\neaUHhTZtoq6liEhmKCyINML+/T6lccECePZZX++gbVsfd/DYYx4QBg2KupYiIk1DYUGkHjU1viPj\nggU+/uCVV3zWQv/+vt7BtGk+a6F9+6hrKiLS9BQWRGI+/BCee87DwXPPwY4dHgbGjPFwMG4cnHaa\nZi2ISOFRWJCCtXOndy0sXOjTGlev9uPDhsEtt3g4uOgijT0QEVFYkIJRUeHbNi9c6GXlSj8+eLC3\nHtx7r695oNUSRUSOprAgeevIEVi+3Ackzp8Pr7/uYxH69vXxBlOnekjo1y/qmoqING8KC5JXtm6F\nefO8LFjgGzN17uzbN99yi4eDQYM07kBEJBUKC5LTDh/2/RXmzfMWhBUrPAicfz7cfjtcfjlccAG0\nbBl1TUVEcpfCguScXbs8HMya5V/37PEtm8ePhx/8wFsRtIWziEjmKCxIsxcCrFnj4WD2bF/z4MgR\nKCmBKVPgqqt8BoP2WhARaRoKC9IsVVf7zIXZsz0klJfDiSfC5z8Pv/mNr5jYu3fUtRQRKQwKC9Js\nbNni+y3MneuLIu3f74Hgqqtg+nSfwXDiiVHXUkSk8CgsSGTiUxvjuzW+8YZ3JQwfDvfc460HxcWa\nuSAiEjWFBcmq/ft9UOLTT/vshZ07oUsXuOIKuPNOH6TYtWvUtRQRkdoUFqTJ7djh4w6eesq7F6qq\nYOhQuPVWbz248EJNbRQRac4UFqRJbNgA//iHB4SXX/YZDSNHwsMPwzXXwMCBUddQREQaK62wYGaT\ngTuBnsBK4PYQwmsNnHspsKjO4QAUhRC2p/P60vwcPgzLlvmqiXPm+PiDNm189sITT8AXv6g9F0RE\nclXKYcHMrgN+AXwHWA5MBeab2ekhhI8auCwApwP7PjmgoJDzyst9z4UFC3xjpn37fLzBuHFw992+\neuJJJ0VdSxEROV7ptCxMBZ4IITwJYGa3Al8AbgYeTXLdjhDC3jReT5qJvXs9FCxY4CHh/fehVSvv\nXrj7bg8JWhxJRCT/pBQWzKw1UAI8HD8WQghm9jwwItmlwAozOwF4C7g/hLAkjfpKlq1f74MTZ82C\nF1/07obTTvPZC+PHw+jR0LFj1LUUEZGmlGrLQjegJbCtzvFtwJAGrvkQ+FfgdaAt8G1gsZldEEJY\nkeLrSxOLr30QDwhvvQWtW/tujdOmwRe+AAMGRF1LERHJpiafDRFCWAusrXVomZkNwrszJiW7durU\nqXTq1OmoYxMnTmTixIkZr2chq6iAF17wcDBnjk917NrVg8H993v3gloPRESan5kzZzJz5syjjlVU\nVGT8dSyE0PiTvRuiEvhyCOGZWsdnAJ1CCNc28nkeBUaGEEY28PgwoLS0tJRhw4Y1un7SODU1Plth\n/nxfIGnJEm9ROPNMmDDBy/DhWvtARCQXlZWVUVJSAlASQijLxHOm1LIQQjhsZqXAWOAZADOz2Pe/\nTOGpzsW7JyRLduzwgYnz5nlI2LEDOnSAsWPh17/28QfqXhARkfqk0w0xDZgRCw3xqZPtgBkAZvYI\n0CuEMCn2/RRgPfA2cAI+ZmEMcNnxVl4aFoKPN3jqKe9eKC31Y+eeC9/6lk9rHDHC10IQERFJJuWw\nEEL4q5l1Ax4EegArgPEhhB2xU3oCfWtd0gZfl6EX3oWxChgbQnjpeCoun1ZT4wsjPfWUl/JyH2tw\n5ZVw++0+9qBnz6hrKSIiuSatAY4hhMeBxxt47KY63/8c+Hk6ryPHVl0NixZ5OHj6adi61VdKvPpq\n+NWvfFvntm2jrqWIiOQy7Q2Rg3bt8rEHs2f71s4VFT7e4Prr4dprvXtBgxNFRCRTFBZyQAjw7rse\nDmbPhlde8dkLw4bBlCnwpS/5Lo5mUddURETykcJCM1VdDS+9lAgI5eVw4om+MdPjj/saCL17R11L\nEREpBAoLzcjmzfDss9618PzzvjFTnz5w1VUwfbqPPzjxxKhrKSIihUZhIUKHD8PSpYmAsGqVb8I0\nYgTcdZe3HhQXq3tBRESipbCQZdu2JcLBggU+OLF7d9+Y6Z57fHpjly5R11JERCRBYaGJhQArV/rC\nSLNn+yZNZnDBBXDHHR4SSkq0rbOIiDRfCgtNoLISFi5MDE7cvNkXR7r8cpg82QNC9+5R11JERKRx\nFBYyZP16X/tgzhzfwfHQIRg0CL76VR+gOGqUllYWEZHcpLCQpoMH4cUXPSA8+yysXQutWsFFF8FP\nfuIBYcgQDU4UEZHcp7DQSCHAunWJcLB4sbce9Onj3Qo/+5lPbezUKeqaioiIZJbCQhJVVd56MGeO\njz14/33vShg1Cn76Ux+DcOaZaj0QEZH8prBQx5YtPq1xzhx47jk4cAD69vU1D668EsaMgQ4doq6l\niIhI9hR8WDhyBEpLE60HZWWJhZF++EMPCeeco9YDEREpXAUZFjZt8gWR5s/3ZZV37YKTT/axB3fc\n4d0LXbtGXUsREZHmoSDCQmWlb8oUDwjvvOMtBZ/9rK97MG4cDB/usxlERETkaHn58RgCrFnjYw/m\nzfOgUFXlMxfGj4f77vPdG7WssoiIyLHlTViorPTpjHPnelm/Hk44AUaP9mmN48fDGWdo7IGIiEiq\ncjoslJcnNmVatMjXPejfPzFzYfRoaNcu6lqKiIjktpwKCx9/DEuW+KZMs2Z5V0Pr1nDJJfDQQx4Q\ntGqiiIhIZjX7sFBR4eMOZs3yVoRdu6BHD19O+ZFHfOxBx45R11JERCR/NeuwcOut8MYb3qJQXAy3\n3QYTJsD552tLZxERkWxp1mGhVSuYPt1bEfr1i7o2IiIihalZh4Vf/xqGDYu6FiIiIoVNjfkiIiKS\nlMKCiIiIJKWwICIiIkkpLIiIiEhSCgsiIiKSlMKCiIiIJKWwICIiIkkpLIiIiEhSCgsiIiKSVFph\nwcwmm9l6MztoZsvM7LONvG6kmR02s7J0Xlea1syZM6OuQsHRPc8+3fPs0z3PfSmHBTO7DvgFcB9w\nHrASmG9m3Y5xXSfgT8DzadRTskD/oLNP9zz7dM+zT/c896XTsjAVeCKE8GQI4V3gVqASuPkY1/0W\n+F9gWRqvKSIiIhFJKSyYWWugBHghfiyEEPDWghFJrrsJGAA8kF41RUREJCqp7jrZDWgJbKtzfBsw\npL4LzOw04GHg4hBCjZmlXEkRERGJTpNuUW1mLfCuh/tCCOXxw4249ASA1atXN1XVpB4VFRWUlWns\naTbpnmef7nn26Z5nV63PzhMy9ZzmvQiNPNm7ISqBL4cQnql1fAbQKYRwbZ3zOwG7gY9JhIQWsf/+\nGBgXQlhcz+tcj4cMERERSc8NIYQ/Z+KJUmpZCCEcNrNSYCzwDIB5v8JY4Jf1XLIXOLvOscnAGODL\nwIYGXmo+cEPs8UOp1FFERKTAnQD0xz9LMyKdbohpwIxYaFiOz45oB8wAMLNHgF4hhEmxwY/v1L7Y\nzLYDh0IIDfYxhBB2AhlJQyIiIgVoSSafLOWwEEL4a2xNhQeBHsAKYHwIYUfslJ5A38xVUURERKKU\n0pgFERERKTzaG0JERESSUlgQERGRpCIJC6luRGVmo82s1MwOmdlaM5uUrbrmi1TuuZlda2YLzGy7\nmVWY2RIzG5fN+uYDbbiWfWn8bmljZg+Z2YbY75f3zeybWapuXkjjnt9gZivM7ICZbTGz35tZl2zV\nN9eZ2Sgze8bMNptZjZl9sRHXHPdnaNbDQqobUZlZf2A2vsR0MTAd+B8zuywb9c0HaWz+dQmwALgC\nGAYsAmaZWXEWqpsXtOFa9qV5z/+GT+W+CTgdmAisaeKq5o00fp+PxH++fwecCXwFuAD476xUOD+0\nxycW3AYcc9Bhxj5DQwhZLfhGUtNrfW/AJuDfGzj/P4BVdY7NBOZmu+65WlK95w08x1vAj6J+L7lS\n0r3nsZ/tB/BfvmVRv49cKmn8brkc2AWcHHXdc7Wkcc+/D6yrc+y7wAdRv5dcLEAN8MVjnJORz9Cs\ntiykuRHVcD79V9b8JOdLLelu/lXnOQzoiP9ilWPQhmvZl+Y9nwC8DtxlZpvMbI2Z/dzMMrZEbj5L\n854vBfqa2RWx5+gBfBWY07S1LWgZ+QzNdjdEso2oejZwTc8Gzj/JzNpmtnp5KZ17XtcP8Kavv2aw\nXvks5Xtea8O1G0IINU1bvbyUzs/5QGAUcBZwDTAFbxb/ryaqY75J+Z6HEJYA/wL8xcyqgQ/xLQG+\n24T1LHQZ+QzVbAhJKrZPx73AV0MIH0Vdn3x0HBuuyfFpgTfjXh9CeD2EMA+4A5ikP0SahpmdifeZ\n34+PhxqPt6Y9EWG1pBGadNfJenwEHMFXfqytB7C1gWu2NnD+3hBCVWarl5fSuecAmNnX8YFHXwkh\nLGqa6uWlVO95R+B84Fwzi/9V2wLvAaqmgQ3X5Cjp/Jx/CGwOIeyvdWw1HtT6AOX1XiVx6dzzu4FX\nQgjTYt+/ZWa3Af80sx+GEOr+BSzHLyOfoVltWQghHAbiG1EBR21E1dA61ktrnx8zLnZcjiHNe46Z\nTQR+D3w99heXNFIa9zy+4dq5+GjlYuC3wLux/361iauc89L8OX8F6GVm7WodG4K3NmxqoqrmjTTv\neTt8x+HaavBR/WpNaxqZ+QyNYPTm1/Btrm8EzsCbn3YC3WOPPwL8qdb5/YF9+IjOIfh0kWrg81GP\nRM2VksY9vz52j2/FE2i8nBT1e8mVkuo9r+d6zYZo4nuOj8P5P+AvwGfwKcNrgN9G/V5ypaRxzycB\nVbHfLQOAkfiGhEuifi+5UmI/t8X4Hxc1wPdi3/dt4J5n5DM0qjd7G7799EE83Zxf67E/AgvrnH8J\nnmAPAuuAb0T9PyzXSir3HF9X4Ug95Q9Rv49cKqn+nNe5VmEhC/ccX1thPrA/FhweBdpG/T5yqaRx\nzycDb8bu+SZ83YWiqN9HrhTg0lhIqPf3c1N9hmojKREREUlKsyFEREQkKYUFERERSUphQURERJJS\nWBAREZGkFBZEREQkKYUFERERSUphQURERJJSWBAREZGkFBZE5BNmdqqZ1ZjZ0BSumWRmu5uyXiIS\nLYUFEakrnWVdtRSsSB5TWBCRurT7n4gcRWFBpMCY2Xgz+6eZ7Tazj8xslpkNbODcS2PdElea2Uoz\nO2hmS83srHrOHWdm75jZPjN71sx61HrsfDNbYGY7zGyPmS02s/Oa8n2KSOYoLIgUnvbAL4BhwOfw\nHeueOsY1jwJTgfOBHcAzZtayznN+H7gBGAX0Ax6r9XhHYAZwEXAhsBaYa2btj/O9iEgWaNdJkQJn\nZt2A7cDZwAFgPXBuCGGVmV2Kb1n+tRDC32Pnd8a3Fp4UQvi7mU0C/gAMCiFsiJ3zb8C9IYReDbxm\nC2A3MDGEMLdJ36CIHDe1LIgUGDMbbGZ/NrNyM6vAw0HAWwPqE4Bln3wTwm5gDfCZWudUxoNCzIfA\nKbVe8xQz+52ZrTWzPUAF3hrR0GuKSDPSKuoKiEjWzcYDwi3AFqAl8BbQ5jie83Cd7wNHD5R8EugM\n3A58AFThAeR4XlNEskQtCyIFxMy6AKcDPw0hLAohrAG6HOsyYHit5+gce453Unjpi4BfhhDmhxBW\n4+GiW0qVF5HIqGVBpLDsBnYC3zGzrcCpwCMce52EH5vZLnxsw0P4IMenU3jddcA3zKwU6IQPmKxM\nse4iEhG1LIgUkOAjmq8DSoA38VkRd8YfrvOVWt/fDUwHXgO6AxNCCB+n8NI3490QpcCfYs+1PY23\nICIR0GwIEWlQbDbEQqBzCGFv1PURkWioZUFEjkUrOooUOIUFETkWNT+KFDh1Q4iIiEhSalkQERGR\npBQWREREJCmFBREREUlKYUFERESSUlgQERGRpBQWREREJCmFBREREUlKYUFERESSUlgQERGRpP4f\njLciwUeRmEEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x154b971d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(0, 1.02, 0.02), accuracies, label='Accuracy')\n",
    "plt.plot(np.arange(0, 1.02, 0.02), RMSEs, label='RMSE')\n",
    "plt.xlabel('alpha')\n",
    "plt.title('Combine Logistic Regression and Matrix Factorization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.640627\n",
      "Test RMSE is 0.917416395399\n"
     ]
    }
   ],
   "source": [
    "alpha = optimalAlpha\n",
    "trueRating_test = allratings[-N_test:]\n",
    "trueRating_test.index = range(N_test)\n",
    "\n",
    "clf_pred_test = logistic_clf.predict(wordvec5[-N_test:])\n",
    "mf_pred_test = MF_pred_test.iloc[:,2]\n",
    "prediction = clf_pred_test*alpha + mf_pred_test*(1-alpha)\n",
    "\n",
    "accuracy = np.sum(trueRating_test == np.round(prediction))*1.0/N_test\n",
    "print(\"Test accuracy is %.6f\" % (accuracy))\n",
    "    \n",
    "RMSE = np.sqrt(np.sum((trueRating_test - prediction)**2)/N_test)\n",
    "print(\"Test RMSE is\", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Logistic regression based on review (including summary) text is most effective to predict the class correctly (higher accuracy). While matrix factorization alone has worse accuracy and RMSE than logistic regression, combining matrix factorization prediction into logistic regression prediction can leads to a better RMSE score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
